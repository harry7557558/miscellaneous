{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\n\nimport torch\nfrom torch import nn, tensor\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import transforms, ToTensor\nimport torchvision.utils as vutils\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-14T03:18:38.520655Z","iopub.execute_input":"2022-07-14T03:18:38.521008Z","iopub.status.idle":"2022-07-14T03:18:38.527136Z","shell.execute_reply.started":"2022-07-14T03:18:38.520979Z","shell.execute_reply":"2022-07-14T03:18:38.526197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LATENT = 32\nDIMS_G = [32, 64, 32, 16]\nDIMS_D = [16, 32, 64, 32]\nMODEL_G_PATH = \"ffhq-64x64-g.pth\"\nMODEL_D_PATH = \"ffhq-64x64-d.pth\"\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#device = torch.device(\"cuda\")\nprint(\"Device:\", device)","metadata":{"execution":{"iopub.status.busy":"2022-07-14T03:18:38.564832Z","iopub.execute_input":"2022-07-14T03:18:38.565384Z","iopub.status.idle":"2022-07-14T03:18:38.573637Z","shell.execute_reply.started":"2022-07-14T03:18:38.565344Z","shell.execute_reply":"2022-07-14T03:18:38.572621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FFHQDataset(Dataset):\n\n    def __init__(self, transform=None, target_transform=None):\n        self.size = 64\n        self.path = \"../input/ffhq-face-64x64/64x64/\"\n        self.raw_bytes = {}\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        #return 10000\n        return 70000\n\n    def __getitem__(self, i):\n        bd = i - i % 1000\n        filepath = self.path + \"{:05d}.raw\".format(bd)\n        if filepath not in self.raw_bytes:\n            content = np.fromfile(filepath, dtype=np.uint8)\n            content = content.reshape((1000, 3, self.size, self.size))\n            self.raw_bytes[filepath] = content\n        else:\n            content = self.raw_bytes[filepath]\n        return content[i%1000].astype(np.float32) / 255.0\n\n\nclass AnimeFaceDataset(Dataset):\n\n    def __init__(self, transform=None, target_transform=None):\n        self.size = 64\n        self.path = \"../input/anime-face/64x64.raw\"\n        raw_bytes = np.fromfile(self.path, dtype=np.uint8)\n        self.content = raw_bytes.reshape((60000, 3, 64, 64))\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        #return 10000\n        return 60000\n\n    def __getitem__(self, i):\n        return self.content[i%1000].astype(np.float32) / 255.0\n\n\ndef load_data(dataset, plot=False):\n    dataloader = DataLoader(\n        dataset,\n        batch_size=128,\n        shuffle=True\n    )\n    for x in dataloader:\n        print(\"Shape of x:\", x.shape)\n        break\n    if plot:\n        plt.figure(figsize=(8, 8))\n        plt.axis(\"off\")\n        plt.title(\"Training Images\")\n        plt.imshow(np.transpose(vutils.make_grid(\n            next(iter(dataloader)).to(device)[:64],\n            padding=2, pad_value=0.5, normalize=True).cpu(), (1, 2, 0)),\n                   interpolation='nearest')\n        plt.show()\n    return dataloader\n\n\ndataloader = load_data(AnimeFaceDataset(), True)","metadata":{"execution":{"iopub.status.busy":"2022-07-14T03:18:38.588386Z","iopub.execute_input":"2022-07-14T03:18:38.588896Z","iopub.status.idle":"2022-07-14T03:18:39.092106Z","shell.execute_reply.started":"2022-07-14T03:18:38.588856Z","shell.execute_reply":"2022-07-14T03:18:39.091096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n\n    def __init__(self):\n        super(Generator, self).__init__()\n        # ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0)\n        # https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n        dims = DIMS_G\n        layers = [\n            # LATENT\n            nn.Linear(LATENT, dims[0]*4*4, bias=False),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.Unflatten(1, (dims[0], 4, 4)),\n            # dims[0] x 4x4\n            nn.ConvTranspose2d(dims[0], dims[1], 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.1, inplace=True),\n            # dims[1] x 8x8\n            nn.ConvTranspose2d(dims[1], dims[2], 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.1, inplace=True),\n            # dims[2] x 16x16\n            nn.ConvTranspose2d(dims[2], dims[3], 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.1, inplace=True),\n            # dims[3] x 32x32\n            nn.ConvTranspose2d(dims[3], 3, 4, 2, 1, bias=False),\n            nn.Sigmoid()\n            # 3 x 64x64\n        ]\n        layers = [layer for layer in layers if layer is not None]\n        self.main = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.main(x)\n\n\nclass Discriminator(nn.Module):\n\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        # Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0)\n        dims = DIMS_D\n        self.main = nn.Sequential(\n            # 3 x 64x64\n            nn.Conv2d(3, dims[0], 4, 2, 1, bias=False),\n            nn.BatchNorm2d(dims[0]),\n            nn.LeakyReLU(0.2, inplace=True),\n            # dims[0] x 32x32\n            nn.Conv2d(dims[0], dims[1], 4, 2, 1, bias=False),\n            nn.BatchNorm2d(dims[1]),\n            nn.LeakyReLU(0.2, inplace=True),\n            # dims[1] x 16x16\n            nn.Conv2d(dims[1], dims[2], 4, 2, 1, bias=False),\n            nn.BatchNorm2d(dims[2]),\n            nn.LeakyReLU(0.2, inplace=True),\n            # dims[2] x 8x8\n            nn.Conv2d(dims[2], dims[3], 4, 2, 1, bias=False),\n            nn.BatchNorm2d(dims[3]),\n            nn.LeakyReLU(0.2, inplace=True),\n            # dims[3] x 4x4\n            nn.Conv2d(dims[3], 1, 4, 1, 0, bias=False),\n            nn.Flatten(),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.main(x)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-14T03:18:39.094643Z","iopub.execute_input":"2022-07-14T03:18:39.095055Z","iopub.status.idle":"2022-07-14T03:18:39.116584Z","shell.execute_reply.started":"2022-07-14T03:18:39.095015Z","shell.execute_reply":"2022-07-14T03:18:39.115642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def weights_init(m):\n    classname = m.__class__.__name__\n    if 'BatchNorm' in classname:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n        nn.init.normal_(m.bias.data, 0.0, 0.02)\n    elif 'Linear' in classname:\n        if 'weight' in m.__dict__ and m.weight is not None:\n            nn.init.normal_(m.weight.data, 0.0, 0.1)\n        if 'bias' in m.__dict__ and m.bias is not None:\n            nn.init.normal_(m.bias.data, 0.0, 0.1)\n    else:\n        if 'weight' in m.__dict__ and m.weight is not None:\n            nn.init.normal_(m.weight.data, 0.0, 0.02)\n        if 'bias' in m.__dict__ and m.bias is not None:\n            nn.init.normal_(m.bias.data, 0.0, 0.02)\n\n\ndef train_epoch(dataloader, net_g, net_d, loss_fn, optimizer_g, optimizer_d):\n    for batch, x in enumerate(dataloader, 0):\n\n        # add real batches\n        net_d.zero_grad()\n        real = x.to(device)\n        batch_size = real.size(0)\n        label = torch.ones((batch_size), device=device)\n        output_d_real = net_d(real).view(-1)\n        err_d_real = loss_fn(output_d_real, label)\n        err_d_real.backward()\n\n        # add fake batches\n        noise = torch.randn(batch_size, LATENT, device=device)\n        fake = net_g(noise)\n        label.fill_(0.0)\n        output_d_fake = net_d(fake.detach()).view(-1)\n        err_d_fake = loss_fn(output_d_fake, label)\n        err_d_fake.backward()\n        optimizer_d.step()\n\n        # train generator\n        net_g.zero_grad()\n        label.fill_(1.0)\n        output_g = net_d(fake).view(-1)\n        #err_g = loss_fn(output_g, label)\n        err_g = 1.0-loss_fn(1.0-output_g, label)\n        err_g.backward()\n        optimizer_g.step()\n\n        # output stats\n        if (batch+1) % 50 == 0:\n            err_d = err_d_real + err_d_fake\n            d_x = output_d_real.mean().item()\n            d_g_z1 = output_d_fake.mean().item()\n            d_g_z2 = output_g.mean().item()\n            print('[%d/%d]  Loss_D: %.4f  Loss_G: %.4f  D(x): %.4f  D(G(z)): %.4f / %.4f'\n                  % (batch+1, len(dataloader),\n                     err_d.item(), err_g.item(), d_x, d_g_z1, d_g_z2))\n\n\ndef count_weights(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n\ndef main_train():\n\n    # create generator and discriminator models\n    net_g = Generator().to(device)\n    print(\"Generator\", count_weights(net_g))\n    print(net_g)\n\n    net_d = Discriminator().to(device)\n    print(\"Discriminator\", count_weights(net_d))\n    print(net_d)\n\n    try:\n        net_g.load_state_dict(torch.load(MODEL_G_PATH, map_location=device))\n        net_d.load_state_dict(torch.load(MODEL_D_PATH, map_location=device))\n        print(\"Model loaded from file.\")\n    except BaseException as e:\n        pass\n    net_g.apply(weights_init)\n    net_d.apply(weights_init)\n    print(\"Model weights initialized.\")\n\n    if False:  # make sure the model has no error\n        z = tensor(np.ones((1, LATENT), dtype=np.float32))\n        print('z', z.shape)\n        g = net_g(z)\n        print('g', g.shape)\n        d = net_d(g)\n        print('d', d.shape)\n        sys.exit(0)\n\n    # loss function and optimizer\n    loss_fn = nn.BCELoss()\n    optimizer_g = torch.optim.Adam(net_g.parameters(),\n                                   lr=0.001, betas=(0.5, 0.999))\n    optimizer_d = torch.optim.Adam(net_d.parameters(),\n                                   lr=0.0002, betas=(0.5, 0.999))\n\n    # train with progress\n    fixed_noise = torch.randn(64, LATENT, device=device)\n    for epoch in range(1, 20+1):\n        # train\n        print(\"Epoch\", epoch)\n        train_epoch(dataloader, net_g, net_d, loss_fn, optimizer_g, optimizer_d)\n        # plot\n        if epoch % 1 == 0:\n            generated = net_g(fixed_noise)\n            plt.figure(figsize=(8, 8))\n            plt.axis(\"off\")\n            plt.title(\"Generated Images\")\n            plt.imshow(np.transpose(vutils.make_grid(\n                generated,\n                padding=2, pad_value=0.5, normalize=True).cpu(), (1, 2, 0)),\n                       interpolation='nearest')\n            plt.show() # on ipynb\n\n    torch.save(net_g.state_dict(), MODEL_G_PATH)\n    torch.save(net_d.state_dict(), MODEL_D_PATH)\n\n\nmain_train()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T03:18:39.118331Z","iopub.execute_input":"2022-07-14T03:18:39.119126Z","iopub.status.idle":"2022-07-14T03:20:04.929674Z","shell.execute_reply.started":"2022-07-14T03:18:39.119084Z","shell.execute_reply":"2022-07-14T03:20:04.927784Z"},"trusted":true},"execution_count":null,"outputs":[]}]}